{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bae2a2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>802906</td>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28830</td>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>2812</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94947</td>\n",
       "      <td>21</td>\n",
       "      <td>363</td>\n",
       "      <td>8973</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>590882</td>\n",
       "      <td>22</td>\n",
       "      <td>418</td>\n",
       "      <td>10694</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201944</td>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "      <td>1488</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260596</th>\n",
       "      <td>688636</td>\n",
       "      <td>25</td>\n",
       "      <td>1335</td>\n",
       "      <td>1621</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>n</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260597</th>\n",
       "      <td>669485</td>\n",
       "      <td>17</td>\n",
       "      <td>715</td>\n",
       "      <td>2060</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260598</th>\n",
       "      <td>602512</td>\n",
       "      <td>17</td>\n",
       "      <td>51</td>\n",
       "      <td>8163</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260599</th>\n",
       "      <td>151409</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>1851</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260600</th>\n",
       "      <td>747594</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>9101</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>n</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260601 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  geo_level_1_id  geo_level_2_id  geo_level_3_id  \\\n",
       "0            802906               6             487           12198   \n",
       "1             28830               8             900            2812   \n",
       "2             94947              21             363            8973   \n",
       "3            590882              22             418           10694   \n",
       "4            201944              11             131            1488   \n",
       "...             ...             ...             ...             ...   \n",
       "260596       688636              25            1335            1621   \n",
       "260597       669485              17             715            2060   \n",
       "260598       602512              17              51            8163   \n",
       "260599       151409              26              39            1851   \n",
       "260600       747594              21               9            9101   \n",
       "\n",
       "        count_floors_pre_eq  age  area_percentage  height_percentage  \\\n",
       "0                         2   30                6                  5   \n",
       "1                         2   10                8                  7   \n",
       "2                         2   10                5                  5   \n",
       "3                         2   10                6                  5   \n",
       "4                         3   30                8                  9   \n",
       "...                     ...  ...              ...                ...   \n",
       "260596                    1   55                6                  3   \n",
       "260597                    2    0                6                  5   \n",
       "260598                    3   55                6                  7   \n",
       "260599                    2   10               14                  6   \n",
       "260600                    3   10                7                  6   \n",
       "\n",
       "       land_surface_condition foundation_type  ... has_secondary_use_hotel  \\\n",
       "0                           t               r  ...                       0   \n",
       "1                           o               r  ...                       0   \n",
       "2                           t               r  ...                       0   \n",
       "3                           t               r  ...                       0   \n",
       "4                           t               r  ...                       0   \n",
       "...                       ...             ...  ...                     ...   \n",
       "260596                      n               r  ...                       0   \n",
       "260597                      t               r  ...                       0   \n",
       "260598                      t               r  ...                       0   \n",
       "260599                      t               r  ...                       0   \n",
       "260600                      n               r  ...                       0   \n",
       "\n",
       "       has_secondary_use_rental has_secondary_use_institution  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "4                             0                             0   \n",
       "...                         ...                           ...   \n",
       "260596                        0                             0   \n",
       "260597                        0                             0   \n",
       "260598                        0                             0   \n",
       "260599                        0                             0   \n",
       "260600                        0                             0   \n",
       "\n",
       "       has_secondary_use_school has_secondary_use_industry  \\\n",
       "0                             0                          0   \n",
       "1                             0                          0   \n",
       "2                             0                          0   \n",
       "3                             0                          0   \n",
       "4                             0                          0   \n",
       "...                         ...                        ...   \n",
       "260596                        0                          0   \n",
       "260597                        0                          0   \n",
       "260598                        0                          0   \n",
       "260599                        0                          0   \n",
       "260600                        0                          0   \n",
       "\n",
       "        has_secondary_use_health_post  has_secondary_use_gov_office  \\\n",
       "0                                   0                             0   \n",
       "1                                   0                             0   \n",
       "2                                   0                             0   \n",
       "3                                   0                             0   \n",
       "4                                   0                             0   \n",
       "...                               ...                           ...   \n",
       "260596                              0                             0   \n",
       "260597                              0                             0   \n",
       "260598                              0                             0   \n",
       "260599                              0                             0   \n",
       "260600                              0                             0   \n",
       "\n",
       "        has_secondary_use_use_police  has_secondary_use_other  damage_grade  \n",
       "0                                  0                        0             3  \n",
       "1                                  0                        0             2  \n",
       "2                                  0                        0             3  \n",
       "3                                  0                        0             2  \n",
       "4                                  0                        0             3  \n",
       "...                              ...                      ...           ...  \n",
       "260596                             0                        0             2  \n",
       "260597                             0                        0             3  \n",
       "260598                             0                        0             3  \n",
       "260599                             0                        0             2  \n",
       "260600                             0                        0             3  \n",
       "\n",
       "[260601 rows x 40 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X_train = pd.read_csv(\"train_values.csv\")\n",
    "y_train = pd.read_csv(\"train_labels.csv\")\n",
    "\n",
    "# Join them on building_id\n",
    "df_train = pd.merge(X_train, y_train, on=\"building_id\")\n",
    "# Convert the 'damage_grade' to a categorical type\n",
    "\n",
    "categories = [\n",
    "    \"land_surface_condition\",\n",
    "    \"foundation_type\",\n",
    "    \"roof_type\",\n",
    "    \"ground_floor_type\",\n",
    "    \"other_floor_type\",\n",
    "    \"position\",\n",
    "    \"plan_configuration\",\n",
    "    \"legal_ownership_status\",\n",
    "    \"damage_grade\",\n",
    "]\n",
    "\n",
    "for category in categories:\n",
    "    df_train[category] = df_train[category].astype(\"category\")\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c72cdf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.48      0.55      5025\n",
      "           2       0.72      0.82      0.77     29652\n",
      "           3       0.72      0.60      0.65     17444\n",
      "\n",
      "    accuracy                           0.72     52121\n",
      "   macro avg       0.69      0.64      0.66     52121\n",
      "weighted avg       0.71      0.72      0.71     52121\n",
      "\n",
      "                                feature  importance\n",
      "2                        geo_level_3_id    0.152891\n",
      "1                        geo_level_2_id    0.134381\n",
      "0                        geo_level_1_id    0.133391\n",
      "4                                   age    0.121340\n",
      "5                       area_percentage    0.113307\n",
      "6                     height_percentage    0.056311\n",
      "18                       count_families    0.025126\n",
      "3                   count_floors_pre_eq    0.016402\n",
      "35                    foundation_type_r    0.014867\n",
      "8   has_superstructure_mud_mortar_stone    0.013175\n",
      "Notice that the geo levels are utmost important\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn for feature importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import joblib\n",
    "\n",
    "\n",
    "def main(df_train, id_pkl=None, use_all_data=False):\n",
    "    # Define the features and target\n",
    "    X = df_train.drop(columns=[\"building_id\", \"damage_grade\"])\n",
    "    y = df_train[\"damage_grade\"]\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Define the preprocessing for categorical features\n",
    "    categorical_features = X_train.select_dtypes(include=[\"category\"]).columns.tolist()\n",
    "    numerical_features = X_train.select_dtypes(\n",
    "        include=[\"float64\", \"int64\"]\n",
    "    ).columns.tolist()\n",
    "    # Create a preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", SimpleImputer(strategy=\"mean\"), numerical_features),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "        ]\n",
    "    )\n",
    "    # Create a pipeline with preprocessing and the model\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if id_pkl is None:\n",
    "        loaded = False\n",
    "    else:\n",
    "        try:\n",
    "            pipeline = joblib.load(f\"model_{id_pkl}.pkl\")\n",
    "            loaded = True\n",
    "        except FileNotFoundError:\n",
    "            loaded = False\n",
    "\n",
    "    if not loaded:\n",
    "        # Fit the model\n",
    "        if use_all_data:\n",
    "            X_train = X\n",
    "            y_train = y\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        if id_pkl is not None:\n",
    "            # Save the model\n",
    "            joblib.dump(pipeline, f\"model_{id_pkl}.pkl\")\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "    # Evaluate the model\n",
    "    print(\n",
    "        classification_report(\n",
    "            y_val, y_pred, target_names=[str(i) for i in y.cat.categories]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Feature importance\n",
    "    importances = pipeline.named_steps[\"classifier\"].feature_importances_\n",
    "    # Get feature names after preprocessing\n",
    "    feature_names = (\n",
    "        pipeline.named_steps[\"preprocessor\"]\n",
    "        .transformers_[1][1]\n",
    "        .get_feature_names_out(categorical_features)\n",
    "    )\n",
    "    # Combine feature names with importances\n",
    "    feature_importances = pd.DataFrame(\n",
    "        {\n",
    "            \"feature\": np.concatenate([numerical_features, feature_names]),\n",
    "            \"importance\": importances,\n",
    "        }\n",
    "    )\n",
    "    # Sort by importance\n",
    "    feature_importances = feature_importances.sort_values(\n",
    "        by=\"importance\", ascending=False\n",
    "    )\n",
    "    print(feature_importances.head(10))\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "_ = main(df_train, \"as_it_is\")\n",
    "\n",
    "print(\"Notice that the geo levels are utmost important\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "549c250a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3584 8193 2 9218 4 5124 7686 1545 2059 10766 5135 4112 1554 2579 5141 3608 12313 4640 6178 10788 9254 4648 4137 1068 5677 558 4143 11310 9265 1075 6709 1595 6204 10812 9790 3135 64 2113 1602 7747 9796 69 7237 3144 7240 11337 4172 5196 3151 12367 595 4691 8790 2655 8800 11872 8803 4196 5733 3686 10851 11876 9833 1131 5227 2669 8301 7791 4725 8822 1143 11896 6265 10874 12409 4220 10367 12415 6785 2182 1671 5256 11400 10378 1675 8844 2701 3725 11402 7315 6295 9368 1694 5282 5285 5798 2727 9383 4780 5804 6319 6831 10931 11959 12473 7355 9924 8389 1734 10953 715 3787 5835 4303 7890 3286 11483 2273 9442 6371 7397 5350 6887 1774 3824 12531 12536 1273 4347 6908 10492 4862 7423 9470 2817 2306 3841 6401 11516 11524 12554 11021 3854 12047 11537 12566 5401 4379 3357 799 7968 11041 6435 1830 7979 9004 9520 1330 9522 1335 3384 1337 10040 2877 1855 6975 833 6978 2371 9027 9537 6984 329 6985 5963 3404 11592 8528 5970 339 8533 9558 11095 10584 2396 1373 3933 6495 5473 5474 1891 3429 2406 871 1395 6516 10100 12150 8568 5497 10620 4990 1920 11136 9604 7046 8584 10124 4494 11151 11666 5012 918 5526 9110 10652 6046 929 10147 5540 10148 11684 8616 1962 11179 11181 1454 6576 10672 437 6583 1976 6072 11705 12223 4544 449 1475 4035 8645 6086 11207 4552 9164 2509 3030 9687 9177 988 7645 7651 12260 9702 489 2025 3562 8175 3568 497 3570 11250 5621 3063 506 5627 7167\n",
      "Not all geo_level_ids in the test set part of the training set\n"
     ]
    }
   ],
   "source": [
    "set_train = set(df_train[\"geo_level_3_id\"].unique())\n",
    "df_test = pd.read_csv(\"test_values.csv\")\n",
    "set_test = set(df_test[\"geo_level_3_id\"].unique())\n",
    "print(*map(int, set_test - set_train))\n",
    "print(\"Not all geo_level_ids in the test set part of the training set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4bd02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_levels = locals().get('arr_levels', None)\n",
    "if arr_levels is None:\n",
    "    values = {\n",
    "        i: np.zeros((1 + max(df_train[s]), 4))\n",
    "        for i, s in enumerate([\"geo_level_1_id\", \"geo_level_2_id\", \"geo_level_3_id\"])\n",
    "    }\n",
    "    arr_levels = []\n",
    "    for i, row in df_train.iterrows():\n",
    "        levels = [row[\"geo_level_1_id\"], row[\"geo_level_2_id\"], row[\"geo_level_3_id\"]]\n",
    "        arr_levels.append(levels)\n",
    "        y = row[\"damage_grade\"]\n",
    "        for j, level in enumerate(levels):\n",
    "            values[j][level, y] += 1\n",
    "\n",
    "    arr_levels = np.array(arr_levels)\n",
    "\n",
    "\n",
    "def get_geo_y(df, num=50, drop_original=False):\n",
    "    # Get the average y for each geo_level_3, using larger levels if n_samples < num\n",
    "    arr_levels = df[[\"geo_level_1_id\", \"geo_level_2_id\", \"geo_level_3_id\"]].values\n",
    "    out = []\n",
    "    out_by_level3 = {}\n",
    "    for lvl in arr_levels:\n",
    "        if lvl[2] in out_by_level3:\n",
    "            # Already computed for this level 3, skip\n",
    "            out.append(out_by_level3[lvl[2]])\n",
    "            continue\n",
    "\n",
    "        # Values by level (and y)\n",
    "        vals1 = values[0][lvl[0]]\n",
    "        vals2 = values[1][lvl[1]]\n",
    "        vals3 = values[2][lvl[2]]\n",
    "\n",
    "        if vals3.sum() >= num:  # Enough samples at local level\n",
    "            loc = vals3\n",
    "            w = 1.0\n",
    "            sup = vals3 * 0\n",
    "        elif vals2.sum() >= num:  # Not enough at local level, but enough at next level\n",
    "            loc = vals3\n",
    "            w = vals3.sum() / vals2.sum()\n",
    "            sup = vals2 - vals3\n",
    "        else:  # Not enough at local and next level, use the next level up\n",
    "            loc = vals2\n",
    "            w = vals2.sum() / vals1.sum()\n",
    "            sup = vals1 - vals2\n",
    "\n",
    "        # Compute the statistic, greedily weighing the local level\n",
    "        loc = loc / (1e-9 + loc.sum())\n",
    "        sup = sup / (1e-9 + sup.sum())\n",
    "        tup = w * loc + (1 - w) * sup\n",
    "        tup = tup[1:]\n",
    "        out.append(tup)\n",
    "        out_by_level3[lvl[2]] = tup\n",
    "\n",
    "    out = np.array(out)\n",
    "    out = {\n",
    "        \"geo_y1\": out[:, 0],\n",
    "        \"geo_y2\": out[:, 1],\n",
    "        \"geo_y3\": out[:, 2],\n",
    "    }\n",
    "    out = pd.DataFrame(out)\n",
    "    if drop_original:\n",
    "        df = df.drop(columns=[\"geo_level_1_id\", \"geo_level_2_id\", \"geo_level_3_id\"])\n",
    "        out = pd.concat([df, out], axis=1)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e70d9781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to choose the minimum number of samples?\n",
      "count       31.000000\n",
      "mean      8406.483871\n",
      "std       7922.972472\n",
      "min        265.000000\n",
      "25%       2503.000000\n",
      "50%       4332.000000\n",
      "75%      14728.500000\n",
      "max      24381.000000\n",
      "Name: geo_level_1_id, dtype: float64\n",
      "count    1414.000000\n",
      "mean      184.300566\n",
      "std       259.928137\n",
      "min         1.000000\n",
      "25%        27.000000\n",
      "50%       120.500000\n",
      "75%       256.000000\n",
      "max      4038.000000\n",
      "Name: geo_level_2_id, dtype: float64\n",
      "count    11595.000000\n",
      "mean        22.475291\n",
      "std         29.507407\n",
      "min          1.000000\n",
      "25%          5.000000\n",
      "50%         14.000000\n",
      "75%         30.000000\n",
      "max        651.000000\n",
      "Name: geo_level_3_id, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"How to choose the minimum number of samples?\")\n",
    "print(df_train.groupby(\"geo_level_1_id\")[\"geo_level_1_id\"].apply(len).describe())\n",
    "print(df_train.groupby(\"geo_level_2_id\")[\"geo_level_2_id\"].apply(len).describe())\n",
    "print(df_train.groupby(\"geo_level_3_id\")[\"geo_level_3_id\"].apply(len).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2c52494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using at least num=2 samples to aggregate geo level\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.57      0.61      5025\n",
      "           2       0.76      0.82      0.79     29652\n",
      "           3       0.74      0.67      0.70     17444\n",
      "\n",
      "    accuracy                           0.75     52121\n",
      "   macro avg       0.72      0.69      0.70     52121\n",
      "weighted avg       0.74      0.75      0.74     52121\n",
      "\n",
      "                                feature  importance\n",
      "29                               geo_y3    0.230576\n",
      "28                               geo_y2    0.193886\n",
      "1                                   age    0.101890\n",
      "2                       area_percentage    0.091794\n",
      "27                               geo_y1    0.089905\n",
      "3                     height_percentage    0.046611\n",
      "15                       count_families    0.020598\n",
      "0                   count_floors_pre_eq    0.014517\n",
      "35                    foundation_type_r    0.012293\n",
      "5   has_superstructure_mud_mortar_stone    0.011258\n",
      "\n",
      "Using at least num=3 samples to aggregate geo level\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.57      0.62      5025\n",
      "           2       0.76      0.82      0.79     29652\n",
      "           3       0.74      0.66      0.70     17444\n",
      "\n",
      "    accuracy                           0.75     52121\n",
      "   macro avg       0.72      0.69      0.70     52121\n",
      "weighted avg       0.74      0.75      0.74     52121\n",
      "\n",
      "                                feature  importance\n",
      "29                               geo_y3    0.230406\n",
      "28                               geo_y2    0.190276\n",
      "1                                   age    0.102674\n",
      "2                       area_percentage    0.092984\n",
      "27                               geo_y1    0.091052\n",
      "3                     height_percentage    0.046754\n",
      "15                       count_families    0.020813\n",
      "0                   count_floors_pre_eq    0.014303\n",
      "35                    foundation_type_r    0.012523\n",
      "5   has_superstructure_mud_mortar_stone    0.011333\n",
      "\n",
      "Using at least num=5 samples to aggregate geo level\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.57      0.61      5025\n",
      "           2       0.76      0.82      0.79     29652\n",
      "           3       0.74      0.66      0.70     17444\n",
      "\n",
      "    accuracy                           0.74     52121\n",
      "   macro avg       0.72      0.69      0.70     52121\n",
      "weighted avg       0.74      0.74      0.74     52121\n",
      "\n",
      "                                feature  importance\n",
      "29                               geo_y3    0.223114\n",
      "28                               geo_y2    0.197418\n",
      "1                                   age    0.102837\n",
      "2                       area_percentage    0.092593\n",
      "27                               geo_y1    0.090205\n",
      "3                     height_percentage    0.047206\n",
      "15                       count_families    0.020645\n",
      "0                   count_floors_pre_eq    0.014659\n",
      "35                    foundation_type_r    0.012788\n",
      "5   has_superstructure_mud_mortar_stone    0.011366\n",
      "\n",
      "Using at least num=25 samples to aggregate geo level\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.55      0.59      5025\n",
      "           2       0.75      0.82      0.78     29652\n",
      "           3       0.73      0.65      0.69     17444\n",
      "\n",
      "    accuracy                           0.74     52121\n",
      "   macro avg       0.71      0.67      0.69     52121\n",
      "weighted avg       0.73      0.74      0.73     52121\n",
      "\n",
      "                                feature  importance\n",
      "29                               geo_y3    0.229381\n",
      "28                               geo_y2    0.168751\n",
      "1                                   age    0.109843\n",
      "2                       area_percentage    0.098175\n",
      "27                               geo_y1    0.093185\n",
      "3                     height_percentage    0.047347\n",
      "15                       count_families    0.021918\n",
      "0                   count_floors_pre_eq    0.014723\n",
      "35                    foundation_type_r    0.012810\n",
      "5   has_superstructure_mud_mortar_stone    0.011382\n",
      "\n",
      "Using at least num=50 samples to aggregate geo level\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.53      0.58      5025\n",
      "           2       0.75      0.81      0.78     29652\n",
      "           3       0.72      0.65      0.68     17444\n",
      "\n",
      "    accuracy                           0.73     52121\n",
      "   macro avg       0.70      0.66      0.68     52121\n",
      "weighted avg       0.73      0.73      0.73     52121\n",
      "\n",
      "                                feature  importance\n",
      "29                               geo_y3    0.204012\n",
      "28                               geo_y2    0.157990\n",
      "1                                   age    0.123965\n",
      "2                       area_percentage    0.109145\n",
      "27                               geo_y1    0.094048\n",
      "3                     height_percentage    0.050821\n",
      "15                       count_families    0.023371\n",
      "0                   count_floors_pre_eq    0.014831\n",
      "35                    foundation_type_r    0.012954\n",
      "5   has_superstructure_mud_mortar_stone    0.011863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num in [2, 3, 5, 25, 50]:\n",
    "    print(f\"Using at least num={num} samples to aggregate geo level\")\n",
    "    df_pre = get_geo_y(df_train, num=num, drop_original=True)\n",
    "    main(df_pre, f\"num_{num}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbd40168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.98      0.98      5025\n",
      "           2       0.98      0.99      0.98     29652\n",
      "           3       0.98      0.97      0.98     17444\n",
      "\n",
      "    accuracy                           0.98     52121\n",
      "   macro avg       0.98      0.98      0.98     52121\n",
      "weighted avg       0.98      0.98      0.98     52121\n",
      "\n",
      "                                feature  importance\n",
      "29                               geo_y3    0.227082\n",
      "28                               geo_y2    0.194802\n",
      "1                                   age    0.104486\n",
      "2                       area_percentage    0.094442\n",
      "27                               geo_y1    0.087810\n",
      "3                     height_percentage    0.046714\n",
      "15                       count_families    0.021189\n",
      "0                   count_floors_pre_eq    0.014245\n",
      "35                    foundation_type_r    0.012600\n",
      "5   has_superstructure_mud_mortar_stone    0.011668\n",
      "Submission saved to submission_num_3.csv\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "\n",
    "num = 3\n",
    "\n",
    "df_alt = get_geo_y(df_train, num=num, drop_original=True)\n",
    "pipeline = main(df_alt, f\"num_{num}_final\", use_all_data=True)\n",
    "\n",
    "df_test = pd.read_csv(\"test_values.csv\")\n",
    "df_test_pre = get_geo_y(df_test, num=num, drop_original=True)\n",
    "\n",
    "y_test_pred = pipeline.predict(df_test_pre)\n",
    "df_test[\"damage_grade\"] = y_test_pred\n",
    "\n",
    "df_submission = df_test[[\"building_id\", \"damage_grade\"]]\n",
    "df_submission.to_csv(f\"submission_num_{num}.csv\", index=False)\n",
    "print(f\"Submission saved to submission_num_{num}.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
